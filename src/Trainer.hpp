/*
 * Trainer.hpp
 *
 *  Created on: Jan 23, 2018
 *      Author: guther
 */

#ifndef SRC_TRAINER_HPP_
#define SRC_TRAINER_HPP_

#include "utilities/State.hpp"
#include "utilities/TypeDefine.hpp"
#include "Solvers/Solver.hpp"
#include "Network/ParametrizationForward.hpp"
#include "CostFunctions/CostFunction.hpp"
#include "Samplers/Sampler.hpp"
#include <Eigen/Dense>

namespace networkVMC{

// forward declaration for more efficient compilation

//class CostFunction;
//class Sampler;
class Hamiltonian;

/**
 * \class Trainer
 * \brief Wrapper class for optimizing parameters
 * \tparam F Type of the parameters to optimize
 * \tparam coeffType Type of the vector coefficients of the input of the function to optimize
 * Use a parametrization, a sampler, a solver, a cost function and a Hamiltonian
 * to optimize the parameters with respect to the cost function
 */
template <typename F=std::complex<double>, typename coeffType=std::complex<double> >
class Trainer {
public:
	// supply a Parametrization, a sampler, a solver, the cost function, and a Hamiltonian
	/**
	 * \param NNW (nonlinear) vector Parametrization to optimize
	 * \param msampler Sampler to generate subspaces to consider for optimizing the cost function
	 * \param sl_ Solver object containing the optimization algorithm
	 * \param cf_ CostFunction object containing the function to optimize
	 * \param H_ Hamiltonian object containing the underlying Hamilton Operator, defining connections between basis vectors
	 */
	Trainer(Parametrization<F, coeffType> &NNW_, Sampler<coeffType> &msampler,
			Solver<F, coeffType> &sl_, CostFunction<F, coeffType> &cf_, Hamiltonian const &H_);
/**
 * \brief Optimizes the parameters of the NNW with respect to its cost function
 *
 * Performs a single iteration of the algorithm specified by sl optimizing the parameters of NNW to
 * minimize the function cf. The optimization does not take the full vector space into account, but only a subspace
 * generated by the sampler msampler.
 */
	void train();
/**
 * \brief Sets a parameter of the optimization algorithm and then calls train()
 * \param [in] learningRate New step size parameter for the solver
 * Overload of train that sets the step size parameter of the solver before calling train()
 */
	void train(double learningRate);

  /**
  * \brief Get the current value of the cost function
  * \return The current value of the cost function
  */
	coeffType getE() const;
  /**
   * \brief Get the current vector
   * \return A State object containing the current vector coefficients on the currently sampled subspace
   */
	State<coeffType> const& getState() const;
// For testing purposes: get the cost function
	/**
	 * \brief Get the cost function
	 * \return A reference to the used CostFunction
	 */
	CostFunction<F, coeffType> const & getCF() const {return cf;}
// update the parameters of the Parametrization

	/**
	 * \brief Update the parameters of NNW
	 * Call the optimization algorithm on a sampled space to update the
	 * parameters of the Parametrization NNW of the vector
	 */
	void updateParameters(State<coeffType> const &input);
	virtual ~Trainer();

	// Has a reference member, so assignment is not a thing
	/// Assignment operators are deleted
	Trainer& operator=(Trainer const &source) = delete;
	/// Assignment operators are deleted
	Trainer& operator=(Trainer &&source) = delete;
private:
	Hamiltonian const &modelHam;
	/// the parameterization of the wave function
	Parametrization<F, coeffType> &NNW;
	/// the sampler generating the random states
	// (changes state when sampling, thus not const)
	Sampler<coeffType> &msampler;
	/// the solver that optimizes the parameters
	// (changes its parameters when iterating, thus not const)
	Solver<F, coeffType> &sl;
	/// The cost function with respect to which we optimize
	// (is set up to fit the sampler)
	CostFunction<F, coeffType> &cf;

	// This is only for debugging
	State<coeffType> inputState;
};

}

#endif /* SRC_TRAINER_HPP_ */
